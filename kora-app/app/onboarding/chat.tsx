import React, { useState, useEffect, useRef } from 'react';
import { View, Text, Button, LoaderScreen, Colors } from 'react-native-ui-lib';
import { Audio } from 'expo-av';
import { Feather } from '@expo/vector-icons';
import { useRouter } from 'expo-router';
import { SafeAreaView } from 'react-native-safe-area-context';

import { useUserStore } from '../../store/user-store';
import { useTransactionStore } from '../../store/transaction-store';
import { AIService } from '../../services/ai-service';
import { BorderRadius, Shadows } from '../../constants/design-system';

type OnboardingStep = 'INTRO' | 'INCOME' | 'EXPENSES' | 'BALANCE_PAYDAY' | 'COMPLETE';

const MicOnIcon = () => <Feather name="mic" size={32} color={Colors.textInverse} />;
const MicOffIcon = () => <Feather name="mic-off" size={32} color={Colors.textInverse} />;

export default function OnboardingChat() {
  const router = useRouter();
  const { setIncome, addFixedExpense, setPayday, completeOnboarding } = useUserStore();
  const { setBalance, recalculateSafeSpend } = useTransactionStore();

  const [step, setStep] = useState<OnboardingStep>('INTRO');
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [koraText, setKoraText] = useState(
    "Hi, I'm Kora. Pause. Breathe. I'm here to help you spend better. Let's get set up."
  );

  const recording = useRef<Audio.Recording | null>(null);
  const sound = useRef<Audio.Sound | null>(null);

  useEffect(() => {
    handleKoraSpeak(
      "Hi, I'm Kora. Pause. Breathe. I'm here to help you spend better. First, tell me: how much money comes in each month?"
    );
    setStep('INCOME');
  }, []);

  const handleStartRecording = async () => {
    try {
      await Audio.requestPermissionsAsync();
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const { recording: newRecording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );
      recording.current = newRecording;
      setIsRecording(true);
    } catch (err) {
      console.error('Failed to start recording', err);
    }
  };

  const handleStopRecording = async () => {
    setIsRecording(false);
    setIsProcessing(true);

    if (!recording.current) return;

    const uri = recording.current.getURI();
    await recording.current.stopAndUnloadAsync();

    if (uri) {
      processUserAudio(uri);
    } else {
      setIsProcessing(false);
    }
  };

  const processUserAudio = async (uri: string) => {
    try {
      const text = await AIService.transcribe(uri);
      const response = await AIService.generateResponse(text, { step });

      if (response.data) {
        handleDataExtraction(response.data);
      }

      setKoraText(response.text);
      await handleKoraSpeak(response.text);
      setIsProcessing(false);
    } catch (error) {
      console.error(error);
      setKoraText("I didn't quite catch that. Could you say it again?");
      setIsProcessing(false);
    }
  };

  const handleDataExtraction = (data: any) => {
    switch (step) {
      case 'INCOME':
        if (data.amount) {
          setIncome(data.amount);
          setStep('EXPENSES');
        }
        break;
      case 'EXPENSES':
        if (data.fixed_expenses && Array.isArray(data.fixed_expenses)) {
          data.fixed_expenses.forEach((ex: any) => addFixedExpense(ex.name, ex.amount));
          setStep('BALANCE_PAYDAY');
        }
        break;
      case 'BALANCE_PAYDAY':
        if (data.balance) setBalance(data.balance);
        if (data.payday) setPayday(data.payday);

        if (data.balance && data.payday) {
          setStep('COMPLETE');
          recalculateSafeSpend();
          completeOnboarding();
          setTimeout(() => router.replace('/'), 3000);
        }
        break;
    }
  };

  const handleKoraSpeak = async (text: string) => {
    if (sound.current) {
      await sound.current.unloadAsync();
    }

    const audioUri = await AIService.speak(text);
    if (audioUri) {
      const { sound: newSound } = await Audio.Sound.createAsync({ uri: audioUri });
      sound.current = newSound;
      await newSound.playAsync();
    }
  };

  return (
    <SafeAreaView style={{ flex: 1, backgroundColor: Colors.screenBG }}>
      {/* Visualizer Area */}
      <View flex center padding-page>
        {/* Kora's Bubble */}
        <View
          bg-cardBG
          padding-card
          br40
          style={[Shadows.medium, { maxWidth: '90%' }]}
        >
          <Text h3 center textDefault>
            {koraText}
          </Text>
        </View>

        {/* Dynamic Visualizer */}
        <View
          marginT-s10
          center
          bg-primary
          style={{
            width: 100,
            height: 100,
            borderRadius: BorderRadius.round,
            opacity: isRecording ? 1 : 0.2,
          }}
        />
      </View>

      {/* Controls */}
      <View padding-page bottom centerH>
        {isProcessing ? (
          <LoaderScreen
            color={Colors.primary}
            message="Processing..."
            messageStyle={{ color: Colors.textMuted }}
            overlay={false}
          />
        ) : (
          <Button
            round
            backgroundColor={Colors.primary}
            iconSource={isRecording ? MicOffIcon : MicOnIcon}
            size={Button.sizes.large}
            style={{ width: 80, height: 80, borderRadius: BorderRadius.round }}
            onPressIn={handleStartRecording}
            onPressOut={handleStopRecording}
          />
        )}
        <Text marginT-s3 textMuted caption>
          {isRecording ? 'Listening...' : 'Hold to Speak'}
        </Text>
      </View>
    </SafeAreaView>
  );
}
